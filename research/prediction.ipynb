{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/googlyji/ml_projects/nlp_projects/Resume_Type/Resume_Type/research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.exception import Custom_Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "Custom_Exception",
     "evalue": "error found in line 2 in script /tmp/ipykernel_225486/1604111179.py and error is division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     a\u001b[38;5;241m=\u001b[39m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCustom_Exception\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m     a\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m(Custom_Exception(e,sys))\n",
      "\u001b[0;31mCustom_Exception\u001b[0m: error found in line 2 in script /tmp/ipykernel_225486/1604111179.py and error is division by zero"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    a=1/0\n",
    "\n",
    "except Exception as e:\n",
    "    raise(Custom_Exception(e,sys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=cv2.imread(\"data_resume.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.cvtColor(v,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "corpus.append(ocr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr=pytesseract.image_to_string(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/googlyji/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils import * \n",
    "from src.constants import * \n",
    "import nltk\n",
    "from dataclasses import dataclass\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "wn=WordNetLemmatizer()\n",
    "sentence = re.sub(\"[^a-zA-Z]\", \" \", ocr)\n",
    "sentence=sentence.lower()\n",
    "sentence=sentence.split()\n",
    "sentence=[wn.lemmatize(word) for word in sentence if word not in stopwords.words(\"english\")]\n",
    "sentence=\" \".join(sentence)\n",
    "corpus.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diana dawa data scientist data scientist year broad based experience building data intensive application overcoming complex architectural scalability issue diverse industry proficient predictive modeling data processing data mining algorithm well scripting language including python java capable creating developing testing deploying highly adaptive diverse service translate business functional qualification substantial deliverable diana novoresume com q palo alto ca linkedin com diana dawa work experience data scientist future energy ltd present palo alto ca develop action plan mitigate risk decision making increasing profitability leveraging data science drive interaction partnership manager ensure active cooperation identifying well defining analytical need generating pull insight business build predictive model using various machine learning tool predict possibility equipment failure develop algorithm using natural language processing deep learning model predictive maintenance design algorithm track detect anomaly multiple sensor data energy industry demonstrate knowledge execution application programming interface development test automation data analyst theta financial group san francisco ca utilized analytical technical expertise provide insight proposal support business improvement evaluated analytical model finding global monitoring report company flagship product conducted business analysis understand business need requirement translate conceptual design actively engaged quantitative analysis sophisticated modeling address business issue business analyst statistician maxicare healthcare conducted business process analysis identified critical issue gap need established process center developed key performance indicator kpi presented management led execution plan analyzed produced kpi report allowing monitor field service engineer customer care center closely led training session software developed presented management approval deployment ng novoresume com diana dawa com di diana dawa general skill data visualization machine learning deep learning pattern recognition database structure algorithm statistical analytis data preparation quality management agile methodology technical skill operating system window macos linux database server sql postgres sql server programming language python scikit learn python opencv j h ai spark hadoop r programming django angular j html sql javascript php software tool tableau deep learning machine learning ip camera aws service microsoft azure certificate certification applied data analytics cloudera data science essential certificate essential high performance parallel statistical computing r education master science computer science informatics san francisco university interest music renewable energy artificial intelligence']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=TfidfVectorizer()\n",
    "a=tf.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"artifacts/trained_model/model.dill\"\n",
    "with open(filepath,\"rb\") as f:\n",
    "    model=dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"artifacts/trained_model/vector.dill\"\n",
    "with open(filepath,\"rb\") as f:\n",
    "    tf=dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tf.transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6322)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
